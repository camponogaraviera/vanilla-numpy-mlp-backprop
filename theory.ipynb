{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14433a40",
   "metadata": {
    "id": "14433a40"
   },
   "source": [
    "<!-- Title: -->\n",
    "<div align=\"center\">\n",
    "  <h1><b> Artificial Neural Networks</b>\n",
    "  <h2><b>Theory</b></h2>\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h_3woJe6Zf5P",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1681068069358,
     "user": {
      "displayName": "Lucas Camponogara Viera",
      "userId": "14322290658374940800"
     },
     "user_tz": 180
    },
    "id": "h_3woJe6Zf5P"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "import tensorflow as tf\n",
    "from numpy import exp\n",
    "from math import log2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac5d87f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# <font color='orange'> Blueprint of a Neural Network </font><a name=\"Implementation\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1873896c-13b3-4ea1-9c4f-51f85105fe8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Type of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a452c-f7b9-47e8-8c3f-df1e128346f7",
   "metadata": {},
   "source": [
    "- **Discriminative model:** these models aim to learn the boundary between classes. They focus on modeling the conditional probability $P(y | x)$, where $x$\n",
    "is the input data and $y$ is the label or output. The goal is to directly predict the label or output given the input data. Examples: BERT (bidirectional and encoder-based) used to predict hidden words in a sentence, text classification tasks, sentiment prediction and document categorization.\n",
    "\n",
    "- **Generative model:** these models focus on modeling the joint probability $P(x,y)$. Examples: Naive Bayes, Gaussian Mixture Models (GMM), Hidden Markov Models (HMM), GPT (decoder-based), and T5.\n",
    "\n",
    "- **Bidirectional model:** the model takes into account the context from both the left (preceding words) and the right (following words) of a given word in a sentence during training and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74589def-ed57-465d-a20f-db5bf8a44933",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b4beb9",
   "metadata": {},
   "source": [
    "- **Layers:**\n",
    "    - **Input layer:** the first layer of the neural network (NN) containing one or more neurons where each neuron corresponds to a single normalized (preprocessed) feature of the input data.\n",
    "    - **Hidden layer:** common name given to all layers located between the input layer and the output layer.\n",
    "    - **Output layer:** is the final layer of the neural network that produces the network's predictions, and it contains a number of neurons (also known as units) corresponding to the number of output classes or features to be predicted in the task being solved.\n",
    "    - **Dense layer:** are fully-connected feedforward layers, i.e., each neuron in the previous layer is connected to every neuron in the next layer.\n",
    "    - **Convolutional layer:** a layer that applies filters (a.k.a kernels) to input data to detect features (edges, textures, shapes) and patterns. These filters are trainable parameters, which means their values are updated during the training process to learn relevant features from the data. Works well for structured data such as images due to, but not only, translation invariance.\n",
    "    - **Dense blocks a.k.a densely connected convolutional layers:** the output feature map of each layer is concatenated with the output of all preceding layers along the channel dimension and fed as input to the next layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6581a81e-acf2-4394-b3b3-6009f4665e75",
   "metadata": {},
   "source": [
    "- **Neurons:** units of the NN used to store a value. A single layer of the NN could have one or more such neurons.\n",
    "\n",
    "- **Weights a.k.a synapses:** are the trainable parameters in a neural network that represent the strengths of connections between neurons and are adjusted during the training/optimization process. If a Dense layer $l_j$ has $n$ neurons and the previous layer $l_{j-1}$ has $m$ neurons, then there will be a total of $n*m$ weight (synapse) connections between the two layers, i.e, $n*m$ values in the weight matrix.\n",
    "\n",
    "- **Bias:** is an additional constant term added to the weighted sum of inputs for each neuron in a layer, i.e, there is one bias per neuron in a `Dense layer`.\n",
    "\n",
    "- **Activation function:** is a non-linear function applied to the output of each neuron in a layer. It introduces non-linearity to the model, allowing it to learn complex patterns in the data. In a `Dense layer`, each neuron has its own activation function applied to its input value, which produces the neuron's output that is passed to the next layer as the input.\n",
    "\n",
    "- **Loss function a.k.a error function:** the target function to be minimized so that predicted values get closer and closer to ground truth values.\n",
    "\n",
    "- **Techniques:** dropout, batch normalization, skip connection, residual block, Max Pooling, Max Unpooling, weight initialization, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c12d88-7715-49dc-ac37-36d4dcd279af",
   "metadata": {},
   "source": [
    "- **Mixture of Experts (MoE)**: is a neural network architecture where multiple \"experts\" (which are typically feedforward layers) are trained in parallel.\n",
    "    - In LLMs, the `feedforward layer` of the transformer block is replaced with N other feedforward layers or experts. The input is offloaded to the different experts through a routing mechanism.\n",
    "    - The `mixture part refers to a gating mechanism` that dynamically selects which expert to activate based on the input's characteristics. This contrasts to a traditional multi-headed attention network, where each head usually processes the same data or task.\n",
    "    - The model is trained on a single large dataset where different experts specialize in different features or regions of the data.\n",
    "    - This helps scale large AI models efficiently by activating only a subset of the total parameters during inference.\n",
    "    - `Dense MOE`: input tokens are distributed across all experts, i.e., all experts in the model are active simultaneously for each input token. Outputs are then combined using a gating mechanism. This is computationally expensive and does not scale well.\n",
    "    - `Sparse MOE`: only a subset of experts is activated per input. Much more efficient, as fewer experts are used per inference.\n",
    " \n",
    "**Question:** How does the gating mechanism of mixture of experts knows which model to select based on the input's characteristics?\n",
    "\n",
    "**Answer:** the gating (a.k.a router) function is a Feedforward Neural Network (FFNN) trained alongside the experts, allowing it to learn optimal routing strategies based on input features.\n",
    "\n",
    "The gating FFNN outputs a matrix of weights $H(x)$:\n",
    "\n",
    "$$ H_i(x) =  (W_i x_{i-1} + b_i) $$\n",
    "\n",
    "The router mechanism then outputs a probability distribution over the available experts. For each expert there is a prob. dist. given by:\n",
    "\n",
    "$$ g_i(x) = \\text{Softmax } (H_i(x))$$\n",
    "\n",
    "The final output is a weighted sum of the expert outputs:\n",
    "\n",
    "$$ y = \\sum_i g_i(x) E_i (x)$$\n",
    "\n",
    "where $E_i(x)$ is the output of expert $i$ and $g_i(x)$ is its assigned probability determined by the gating mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ed1a60-f760-41b1-992a-8af077764ea5",
   "metadata": {},
   "source": [
    "- [Hydra-MoE](https://huggingface.co/HydraLM): ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956793b9-36d5-4c5d-8b4d-f59311608377",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Number of trainable parameters per layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33e0713-42de-400a-b6be-3e020aedbbfb",
   "metadata": {},
   "source": [
    "Trainable parameters are the weights and the biases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e007a0b-ba6b-40c0-b15c-d9513e56f533",
   "metadata": {},
   "source": [
    "- **Activation function:** 0 (no trainable parameters).\n",
    "\n",
    "- **Dense layer:** (input_size + 1 bias) * number_of_neurons.\n",
    "\n",
    "- **Bias:** 1*number_of_neurons in the current layer.\n",
    "\n",
    "- **Flatten:** 0 (no trainable parameters).\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2170c4d-9c1f-4326-bd91-7d8229d17627",
   "metadata": {},
   "source": [
    "- **Conv2D layer:** (filter_height * filter_width * input_channels + 1 bias) * number_of_filters.\n",
    "\n",
    "Example: \n",
    "\n",
    "```python\n",
    "nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3), padding=1, stride=1, bias=True)\n",
    "```\n",
    "\n",
    "- Input channels ($C_{in}$): 1.\n",
    "- 0utput channels ($N_{filters}$): 32.\n",
    "- Kernel size (height x width): 3x3.\n",
    "- Each filter (output channel) has one bias term.\n",
    "- Padding and stride do not affect the number of parameters, they only determine the output dimensions of the feature map.\n",
    "- \n",
    "Total parameters: (3x3x1+1)x32 = 320. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f79336-f0f9-4461-916b-de9a0a0f55a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb007c3-2e6b-440c-a0c1-7e24aa703a6d",
   "metadata": {},
   "source": [
    "When dealing with multi-class classification in deep learning, one-hot encoding isn't always the best approach, especially when the number of classes is large. Here are alternative methods:\n",
    " \n",
    "- `Label Encoding (a.k.a Integer Encoding)`:\n",
    "    - Assigns a unique integer to each class.\n",
    "    - Useful for tree-based models but problematic for neural networks due to ordinal relationships being introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00de390f-8e8f-448d-a07a-89cd75b925e4",
   "metadata": {},
   "source": [
    "- `Target Encoding (a.k.a Mean Encoding)`:\n",
    "   - Replaces each categorical input variable (not the target) with the mean of the target variable using only the training data. The target should have a meaningful average per category (e.g., customer churn rate, average price).\n",
    "   - It can lead to data leakage if the entire dataset (training, validation, and test sets) is used to calculate the mean if it is not handled properly (e.g., using K-fold cross-validation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d03e6a9-ca5b-4fc6-b78a-c9247c8a5f0e",
   "metadata": {},
   "source": [
    "- Example of a simple logistic regression model with one neuron for a binary classification task such as predicting the churn (0 or 1):\n",
    "    - Input categorical variable: \"Subscription Plan\" (Basic, Standard, Premium).\n",
    "    - Target variable: \"Churn\" (1: 'Customer left', 0: 'Customer stayed')\n",
    "    - Activation function: sigmoid (binary classification).\n",
    "    - Loss: Binary Cross-Entropy Loss.\n",
    "\n",
    "| Customer ID | Subscription Plan | Churn |\n",
    "| ----------- | ----------------- | ----- |\n",
    "| 1           | Basic             | 1     |\n",
    "| 2           | Standard          | 0     |\n",
    "| 3           | Standard          | 1     |\n",
    "| 4           | Premium           | 0     |\n",
    "| 5           | Premium           | 1     |\n",
    "| 6           | Premium           | 0     |\n",
    "\n",
    "1. **Calculate the mean of the target variable:**\n",
    "\n",
    "- Basic: (1) / 1 = 1\n",
    "- Standard: (0 + 1) / 2 = 0.5\n",
    "- Premium: (0 + 1 + 0) / 3 = 0.333\n",
    "\n",
    "2. **Replace categorical values with encoded values:**\n",
    "\n",
    "| Customer ID | Subscription Plan | Churn | Encoded Plan (x) |\n",
    "| ----------- | ----------------- | ----- | ------------------------------ |\n",
    "| 1           | Basic             | 1     | 1                          |\n",
    "| 2           | Standard          | 0     | 0.5                          |\n",
    "| 3           | Standard          | 0     | 0.5                          |\n",
    "| 4           | Premium           | 0     | 0.333                          |\n",
    "| 5           | Premium           | 1     | 0.333                          |\n",
    "| 6           | Premium           | 0     | 0.333                          |\n",
    "\n",
    "3. **Computing weighted sum $s=w⋅x+b$ and activation $\\hat{y} = \\sigma(s)$.**\n",
    "\n",
    "Setting $w = 4.0$ and $b=-1.5$:\n",
    "\n",
    "| Customer ID | Encoded Plan (x) | s = wx + b | $\\hat{y}$ (predicted prob) | $y$ (groun truth - churn) |\n",
    "| ----------- | ---------------- | ---------- | -------------------------- | ---------- |\n",
    "| 1           | 1                | 2.5        | 0.924                      | 1          |\n",
    "| 2           | 0.5              | 0.5        | 0.622                      | 0          |\n",
    "| 3           | 0.5              | 0.5        | 0.622                      | 0          |\n",
    "| 4           | 0.333            | -0.168     | 0.458                      | 0          |\n",
    "| 5           | 0.333            | -0.168     | 0.458                      | 1          |\n",
    "| 6           | 0.333            | -0.168     | 0.458                      | 0          |\n",
    "\n",
    "4. **Computing the Binary Cross-Entropy Loss:**\n",
    "\n",
    "$$BCE_{loss} = \\frac{1}{N}\\sum_{i=1}^N BCE(y_i, \\hat{y}_i) = - \\frac{1}{6}\\sum_{i=1}^6 y_i \\cdot \\mathrm{log}\\; {\\hat{y}}_i + (1-y_i) \\cdot \\mathrm{log}\\; (1-{\\hat{y}}_i) \\approx ...$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e4ce298-c6d4-4407-a2f2-68cb34529f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4580985059860437"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = -0.168\n",
    "activation = 1/(1+np.exp(-s))\n",
    "activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dbafe9-5aa4-4959-9779-eecd03b720c8",
   "metadata": {},
   "source": [
    "- `Word Embeddings (for Categorical Data)`:\n",
    "    - Trainable embeddings that map categories into continuous vector spaces.\n",
    "    - Helps capture semantic relationships between categories.\n",
    "    - Used in NLP but can be applied to general categorical data.\n",
    " \n",
    "In LLMs:\n",
    "\n",
    "- `Token embedding (a.k.a context vector):` is the representation (encoding) of a token by a continuous vector in a vector space. For autoregressive models (e.g., GPT), which predict one word at a time, the input-target pairs are generated on-the-fly with the sliding window approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323011e1-5e0e-4a65-921e-eb1f39d040c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c19c68c-349a-405d-a5ba-118ff9304a3a",
   "metadata": {},
   "source": [
    "- **Pre-training:** training the model on a particular dataset before fine-tuning.\n",
    "\n",
    "- **Transfer learning:** the neural network architecture and pre-trained weights of a pre-trained model are used as the backbone of a new neural network model. The final layer(s) of this new model is(are) then adjusted (e.g., changing the activation function) to match the desired task. The pre-trained weights can be frozen to retain their original feature representations, while the new layers are trained to adapt to the new task. Finally, pre-trained weights can be unfrozen and updated during the final training.\n",
    "\n",
    "- **RLHF (reinforcement learning with human feedback):** a method to improve the model's performance based on human feedback.\n",
    "- **Zero-shot learning:** the model is able to generalize to unseen tasks without prior examples.\n",
    "- **Few-shot learning:** the model is able to learn from a small number of examples provided as input.\n",
    "- **Few-shot setting:** when examples of the target are provided in the input.\n",
    "- **Zero-shot setting:** no examples of the target are provided in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beab179-939e-45ff-8dd8-1cee2f96b2fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d71bd84-e02f-477c-9406-7bb5f4c8c0ae",
   "metadata": {},
   "source": [
    "- **Fine-tuning**: is a subset of transfer learning. It is a broader term that encompasses any method of adapting a `pretrained model` to a new task, typically using a specific `labeled dataset`. The existing model is initialized with its pretrained weights (e.g., a model trained on ImageNet for images or a large corpus for NLP). A labeled dataset specific to the target task is used. Some or all of the weights are updated during training.\n",
    "\n",
    "- **Regular fine-tuning**: the pretrained weights are directly updated during training, and the entire model (including the updated weights) is saved.\n",
    "\n",
    "- **Instruction fine-tuning**: consists of instruction-answer pairs. For example, an input text in English and the corresponding translated version in Chinese.\n",
    "\n",
    "- **Classification fine-tuning**: consists of input-label pairs. For example, input email with corresponding label (spam or non-spam).\n",
    "\n",
    "- **Low-Rank Adaptation (LoRA)**: is a Parameter-Efficient Fine-Tuning method designed to make fine-tuning more efficient by training only low-rank matrices ($W_A$ and $W_B$) instead of the entire model, while keeping the pre-trained weights frozen.\n",
    "    - The idea behind LoRA is to reduce memory usage and computational overhead by training only the low-rank matrices rather than the full pretrained matrix of weights.\n",
    "    - LoRA's approach is particularly useful for tasks requiring adaptation to new data with limited computational resources, as it avoids storing and fine-tuning the entire pretrained matrix of weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfd38ee-2225-4c56-b796-a281d61256e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "618db7c4-49dc-4912-a8eb-e7c7accecab5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06cf633e",
   "metadata": {
    "id": "06cf633e",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# <font color='orange'> Rule-of-Thumbs </font><a name=\"Implementation\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baa8175",
   "metadata": {
    "id": "1baa8175"
   },
   "source": [
    "1. `Ockham's razor:` when there are two competing theories that make exactly the same predictions, the simpler one is better. In model complexity, the more complex the model, the more prone the model is to overfitting as the size of the dataset decreases. Therefore, one should always start with a baseline model.\n",
    "\n",
    "2. `Learning principle:` random features (noise) cannot be learned. In a data-driven approach, the dataset must share a pattern of meaningful representation.\n",
    "\n",
    "3. `Hold-out set:` it is a good practice to split the dataset into training, test, and validation.\n",
    "\n",
    "4. `Dataset size:` the larger the dataset, the higher the generalization of the model to unseen data.\n",
    "\n",
    "5. `Network depth:` the deeper the network (number of layers), the more information is extracted (learned).\n",
    "\n",
    "6. `Bias-variance trade-off:` while under-parametrization can cause bias (underfitting), over-parametrization can cause variance (overfitting). In mainstream machine learning, one tries to find a balance.\n",
    "\n",
    "7. `Double descent:` over-parametrization beyond certain interpolation threshold can lead to model generalization (good test performance). Moreover, as the size of the parameter vector to be optimized increases (as large as one million), the local minima get closer to the global minimum.\n",
    "\n",
    "8. `Batch size:` a larger batch size (increase memory resource) leads to a speed up in training and to a lower asymptotic test accuracy (classification), and hence a lower generalization to unseen data.\n",
    "\n",
    "9. `Learning rate:` a higher learning rate can speed-up training, however, too large a learning rate can make the loss function value to jiggle around the loss landscape and to never converge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7704cba4",
   "metadata": {
    "id": "7704cba4",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# <font color='orange'> Challenges in Neural Networks </font><a name=\"Implementation\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5845cf2",
   "metadata": {
    "id": "a5845cf2",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21cc377",
   "metadata": {
    "id": "e21cc377"
   },
   "source": [
    "- Overfitting occurs when the model has become too complex and has started to memorize the training data, leading to poor generalization performance on unseen data.\n",
    "- It can be seen when the training loss/accuracy is getting better over time while the validation loss/accuracy is degrading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2924544",
   "metadata": {
    "id": "a2924544",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360650a",
   "metadata": {
    "id": "b360650a"
   },
   "source": [
    "- Underfitting occurs when the model is too simple or when the training dataset is too shallow. \n",
    "- It appears when both training loss/accuracy and validation loss/accuracy are degrading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3d5390-130c-4377-bec3-c48a64112d3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Vanishing Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a12ae-29c8-4395-843a-3b5b8896408b",
   "metadata": {},
   "source": [
    "Vanishing gradient refers to a situation where the gradients of the loss function with respect to the weights become extremely small during the training process. \n",
    "\n",
    "This typically happens in deep neural networks with `many layers`, especially when using activation functions with derivatives that are close to zero, such as the `sigmoid or tanh` functions. As the value of the gradients goes to zero, they fail to provide information for weights update, leading to `slow or stalled learning`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f589689-bada-4dd6-b400-5ca05c036c6e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exploding Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd3a22c-805a-4734-b5e8-606e9273c588",
   "metadata": {},
   "source": [
    "The exploding gradient happens when the gradients of the loss function with respect to the weights become extremely large during training. \n",
    "\n",
    "This can happen in deep neural networks using `large learning rates` in the optimization process. The excessively large gradients lead to large updates to the model parameters. This will make the optimization overshoot the minima and compromise the convergence of weights to their optimal value, consequently causing `instability and erratic learning behavior`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b435331",
   "metadata": {
    "id": "4b435331",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# <font color='orange'> Techniques to Address the Challenges </font><a name=\"Implementation\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2397ad",
   "metadata": {},
   "source": [
    "Popular techniques used in modern neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f3a89a-3516-460d-8e65-d7f7302573a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Weight initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91b8bbf-9fd9-4902-bdca-a4f7012e13a4",
   "metadata": {},
   "source": [
    "Weight initialization is a procedure used to set appropriate initial values to the weights in the neural network, aiming to keep the variance of activations constant across layers. A good initialization helps to prevent vanishing and exploding gradients.\n",
    "\n",
    "Examples of initialization strategies include `Xavier` (also known as Glorot), `He`, and `LeCun`, each of which can use either a `normal` or `uniform` distribution variant. Normal and Uniform are types of distributions used in different initializations, not initialization strategies by themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52219e9",
   "metadata": {
    "id": "c52219e9",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Batchnormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dce2b0",
   "metadata": {
    "id": "a3dce2b0"
   },
   "source": [
    "- Batchnormalization: used to normalize the outputs of the previous layer to have zero mean and unit variance by subtracting the batch mean and dividing by the batch standard deviation for each batch of outputs.\n",
    "- This helps with `training stability`, can `speed up training`, and `prevents overfitting` by adding noise to the outputs.\n",
    "\n",
    "Note: in both fully connected and convolutional layers, `Batchnormalization` is typically applied after the affine transformation (i.e., $Wx + b$) or the convolution operation). While `Batchnormalization` is typically applied before the activation function (e.g., Conv → BN → ReLU), this is not a strict rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903908d5",
   "metadata": {
    "id": "903908d5",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee290c68",
   "metadata": {
    "id": "ee290c68"
   },
   "source": [
    "- Dropout: is a regularization used to `prevent overfitting` (increasing generalization) by randomly deactivating neurons during training.\n",
    "- It also reduces the need for `early stopping`.\n",
    "\n",
    "Note: it is generally not recommended to apply `Dropout` immediately after `Batchnormalization` in the same layer/block, as their effects can interfere. However, using both in different parts of the model can lead to better performance. In this case, `Batchnormalization` is generally applied before `Dropout`. In Keras (Functional API), `Dropout` is typically applied after the activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e440d65b",
   "metadata": {
    "id": "e440d65b",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Skip Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73df680-e6cb-480e-871f-edc98612583c",
   "metadata": {},
   "source": [
    "A general term used to describe any connection in a neural network that bypasses one or more layers. These can take several forms:\n",
    "\n",
    "- Element-wise addition of the input to the output (e.g., as in ResNets).\n",
    "- Concatenation of input and output (e.g., as in DenseNets and U-Nets).\n",
    "- Direct copying or routing of features from earlier to later layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2def71-5b7b-4340-91d6-a9f684864213",
   "metadata": {},
   "source": [
    "Skip connections in `U-Nets` connect corresponding layers in the encoder and decoder paths. This facilitates:\n",
    "\n",
    "- Transfer of low-level spatial features from the encoder (downsampling path).\n",
    "- Recovery of spatial resolution and fine-grained details during the decoder (upsampling path).\n",
    "- Better segmentation output due to preserved localization information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d4d27-074c-4a71-9bb9-2a61771c270a",
   "metadata": {},
   "source": [
    "Residual Block (a.k.a. Residual Layer) is a specific type of skip connection introduced in `ResNets`. The core idea is:\n",
    "\n",
    "- The input tensor is added element-wise to the output of a few stacked layers (typically 2 or 3 convolutions),\n",
    "- This is often called a shortcut connection or identity mapping.\n",
    "\n",
    "- Example of basic residual block with two convolutional layers:\n",
    "    - Input → Conv → Activation → Conv → Output.\n",
    "    - Add input to the output of the second Conv layer.\n",
    "    - The sum is optionally passed through a final activation function (e.g., ReLU).\n",
    " \n",
    "This structure helps:\n",
    "\n",
    "- Mitigate vanishing gradients.\n",
    "- Improve training stability in deep networks.\n",
    "- Enable the training of much deeper architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0255e7-8a5b-41af-af08-e4aa8021ac0e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Linear Regularizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd8bb7-f3de-4823-8e36-074911cf78be",
   "metadata": {},
   "source": [
    "- Ridge regression: a linear regression technique that uses `L2 regularization`, which adds to the cost function a penalty/regularization term proportional to the square of the magnitude of the weights. It prevents overfitting (that might be caused by `multicollinearity`) by shrinking weights, but it does not reduce any of them to zero.\n",
    "\n",
    "Considering the residual sum of squares (RSS) loss function:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "RSS_{L_2}  &=& \\text{RSS} + L_2 \\\\\n",
    "&=& \\sum_{i=1}^{N} (y_i-\\hat{y}_i)^2 + \\lambda \\sum_{i=1}^L ||\\mathbf{W}^{(l)}||^2. \\\\\n",
    "&=& \\sum_{i=1}^{N} (y_i-\\hat{y}_i)^2 + \\lambda \\sum_{i=1}^L \\sum_{j,k} \\mathbf{w}_{jk}^2. \\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "where $L_2 = \\lambda \\sum_{i=1}^L ||\\mathbf{W}||^2$.\n",
    "\n",
    "Legend:\n",
    "\n",
    "- $y_i$: ground truth value (label) for the $i$-th data point (sample).\n",
    "- $\\hat{y}_i$: predicted value for the $i$-th data point (sample).\n",
    "- $L$ is the number of weight matrices in the neural network.\n",
    "- $\\mathbf{w}_{jk}^{2}$ is the square value of the $j$-th weight for the $i$-th matrix.\n",
    "- $\\lambda$ is the regularization coefficient, a value between 0 and 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cacdd6-3ae3-4922-9adb-907df6e04b2d",
   "metadata": {},
   "source": [
    "- Lasso regression: a linear regression technique that uses `L1 regularization`, which adds a penalty/regularization proportional to the absolute value of the weights. This encourages sparsity by shrinking some weights exactly to zero, effectively performing feature selection.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "LS_{L_1}  &=& \\min_{\\mathbf{w}} \\left\\{ \\text{RSS} + L_1 \\right\\} \\\\\n",
    "&=& \\min_{\\mathbf{w}} \\left\\{  \\text{RSS} + \\lambda \\sum_{i=1}^L ||\\mathbf{W}^{(l)}|| \\right\\} \\\\\n",
    "&=& \\min_{\\mathbf{w}} \\left\\{\\sum_{i=1}^{N} (y_i-\\hat{y}_i)^2 + \\lambda \\sum_{i=1}^L \\sum_{j,k} \\mathbf{w}_{jk}  \\right\\}.\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b62cc5-a2e7-46e3-9a95-76148b0ffed1",
   "metadata": {},
   "source": [
    "References: \n",
    "\n",
    "[1] https://www.ibm.com/think/topics/ridge-regression\n",
    "\n",
    "[2] https://www.ibm.com/think/topics/lasso-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd0c901-6a6a-49c8-b45f-c66117dad6af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Number of trainable parameters per technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dd7dd2-4d57-4936-9004-bfccf1b812a0",
   "metadata": {},
   "source": [
    "- **BatchNormalization:** 2 * number_of_filters. Two trainable parameters per filter (gamma and beta). \n",
    "<br>\n",
    "\n",
    "- **Dropout:** 0 (no trainable parameters).\n",
    "<br>\n",
    "\n",
    "- **Skip connection:** 0 (no trainable parameters).\n",
    "<br>\n",
    "\n",
    "- **MaxPooling2D:** 0 (no trainable parameters).\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d5fcaf",
   "metadata": {
    "id": "74d5fcaf",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# <font color='orange'> Activation Functions in Python</font><a name=\"Implementation\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49656421",
   "metadata": {
    "id": "49656421"
   },
   "source": [
    "Activation functions are used to add nonlinearity to the neural network model so that the neural network becomes an **expressive nonlinear function approximator**.\n",
    "\n",
    "- For binary classification (only two target classes): use `sigmoid`.\n",
    "- For multi-label classification (more than two non-exclusive targets, in which multiple target classes can happen at the same time): `use sigmoid`.\n",
    "- For multi-class classification (more than two mutually exclusive targets): use `softmax`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3YbdBPcKFfRs",
   "metadata": {
    "id": "3YbdBPcKFfRs",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T0HKcS0D6Y_o",
   "metadata": {
    "id": "T0HKcS0D6Y_o"
   },
   "source": [
    "The sigmoid activation function is used for binary classification with a `single neuron`. It is also used for multi-label classification when there is more than one right answer, in this case the probabilities produced by a sigmoid are independent (non-exclusive outputs), i.e, they are not constrained to add up to one. \n",
    "\n",
    "\\begin{align}\n",
    "sigmoid(x) = \\frac{1}{1+e^{-x}}.\n",
    "\\end{align}\n",
    "\n",
    "- Input: [-infinity, infinity]. \n",
    "- Output: [0, 1]. \n",
    "- The sum of the probabilities is not equal to 1. \n",
    "\n",
    "Why is sigmoid activation used for binary or multi-label classification tasks if their outputs do not add up to 1 as probabilities should? Because the outputs do not represent a probability distribution over all classes, rather individual probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbuOyci6KMQL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1681068069671,
     "user": {
      "displayName": "Lucas Camponogara Viera",
      "userId": "14322290658374940800"
     },
     "user_tz": 180
    },
    "id": "fbuOyci6KMQL",
    "outputId": "050b29c7-f41b-40f3-cd78-8434e1b0b594"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Applies the sigmoid activation function on input values.\n",
    "\n",
    "    Args:\n",
    "      - x (numpy.ndarray): array of values from each neuron of a given layer, ranging from -infinity to infinity.\n",
    "\n",
    "    Returns:\n",
    "      - activation (numpy.ndarray): array of sigmoid activation values between 0 and 1. \n",
    "                                    Outputs are non-exclusive, i.e, the sum of the values don't add up to 1.\n",
    "    '''\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "#input_ = [x for x in range(-20, 20)] # List of 40 numbers from -20 to 20.\n",
    "input_ = np.linspace(-10, 10, 100).astype('float32') # Array of 100 numbers from -10 to 10.\n",
    "#input_ = np.arange(-20, 20, .1).astype('float32') # Array with Start: -20, Stop: 20, Step: 1.\n",
    "output = [sigmoid(x) for x in input_]\n",
    "\n",
    "plt.plot(input_, output)\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Sigmoid Output\")\n",
    "plt.title(\"Sigmoid Function\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GOeK7f48Fkx-",
   "metadata": {
    "id": "GOeK7f48Fkx-",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LTm_0php7Crd",
   "metadata": {
    "id": "LTm_0php7Crd"
   },
   "source": [
    "The softmax activation function is used for multi-class classification. It normalizes the outputs to produce a probability distribution over all classes.\n",
    "\n",
    "\\begin{align}\n",
    "softmax(x_i) = \\frac{e^{x_i}}{\\sum{e^{x_j}}}.\n",
    "\\end{align} \n",
    "\n",
    "- Input: [-infinity, infinity]. \n",
    "- Output: [0, 1]. \n",
    "- The sum of the probabilities must be equal to 1.\n",
    "\n",
    "A more stable version for NumPy implementation is:\n",
    "\n",
    "\\begin{align}\n",
    "softmax(x_i) = \\frac{\\gamma e^{x_i}}{\\gamma \\sum{e^{x_j}}} = \\frac{e^{x_i+ln(\\gamma)}}{\\sum{e^{x_j+ln(\\gamma)}}}.\n",
    "\\end{align} \n",
    "\n",
    "A common choice is $ln(\\gamma) = -max(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab9f557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of probabilities: 0.9999999\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def softmax(x: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Compute the softmax activation function while handling numerical stability.\n",
    "\n",
    "    Args:\n",
    "      - x (numpy.ndarray): array of values in the range [-infinity, +infinity].\n",
    "\n",
    "    Returns:\n",
    "      - activation (numpy.ndarray): array of softmax activation values in the range [0, 1].\n",
    "                                    Outputs are exclusive, i.e, the sum of the values add up to 1.    \n",
    "    '''\n",
    "    epsilon = 1e-8 # Small number to avoid division by zero.\n",
    "    expX = np.exp(x - np.max(x)) # Subtracting the maximum value for numerical stability.\n",
    "    #return expX / (np.sum(expX) + epsilon)\n",
    "    return expX / (expX.sum(keepdims=True) + epsilon)\n",
    "\n",
    "input_ = np.linspace(-10, 10, 100).astype('float32') # Array of 100 numbers from -10 to 10.\n",
    "#input_ = np.random.rand(2, 10).astype('float32')\n",
    "output = softmax(input_)\n",
    "\n",
    "print('Sum of probabilities:',output.sum())\n",
    "plt.plot(input_, output)\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Softmax Output\")\n",
    "plt.title(\"Softmax Function\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e46b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.33333333, 0.33333333])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ = np.array([0,  0, 0])\n",
    "softmax(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6he0uNVlFoVH",
   "metadata": {
    "id": "6he0uNVlFoVH",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fptk5Uy-72wv",
   "metadata": {
    "id": "fptk5Uy-72wv"
   },
   "source": [
    "- `'tanh'`: \n",
    "  - Input: [-infinity, infinity].\n",
    "  - Output: [-1, 1].\n",
    "\n",
    "\\begin{align}\n",
    "tanh(x_i) = \\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}} = \\frac{e^{2x}-1}{e^{2x}+1}\n",
    "\\end{align}   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "_wtkrHUi-Cjb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1681068070483,
     "user": {
      "displayName": "Lucas Camponogara Viera",
      "userId": "14322290658374940800"
     },
     "user_tz": 180
    },
    "id": "_wtkrHUi-Cjb",
    "outputId": "c6c2839d-8d15-4a96-90ba-bbfa71abb2c1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tanh(x):\n",
    "    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "\n",
    "#input = [x for x in range(-20, 20)]\n",
    "input_ = np.arange(-20, 20, .1).astype('float32')\n",
    "output = [tanh(x) for x in input_]\n",
    "plt.plot(input_, output)\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Tanh Output\")\n",
    "plt.title(\"Tanh Function\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4gJVJsFvFqrO",
   "metadata": {
    "id": "4gJVJsFvFqrO",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ONdACIpQTs-r",
   "metadata": {
    "id": "ONdACIpQTs-r"
   },
   "source": [
    "\\begin{eqnarray}\n",
    "ReLU(x) = max\\{0, x\\}.\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "qC9-TWK3FDIj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1681068071008,
     "user": {
      "displayName": "Lucas Camponogara Viera",
      "userId": "14322290658374940800"
     },
     "user_tz": 180
    },
    "id": "qC9-TWK3FDIj",
    "outputId": "11b3cfeb-be83-4960-8fd0-b25edf2af30f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ReLU(x):\n",
    "    return max(0.0, x)\n",
    "\n",
    "#input = [x for x in range(-10, 10)]\n",
    "input_ = np.arange(-10, 10, 1).astype('float32')\n",
    "output = [ReLU(x) for x in input_]\n",
    "plt.plot(input_, output)\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"ReLU Output\")\n",
    "plt.title(\"ReLU Function\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19800e75-56fe-48ee-a117-82e8d173d2a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## GeLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e1a044-3fb6-4254-b47a-fc2ac4c380a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "psK5gEtJrqKw",
   "metadata": {
    "id": "psK5gEtJrqKw",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# <font color='orange'> Loss Functions in Python and Keras API </font><a name=\"Implementation\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jZWMQ7sg09rE",
   "metadata": {
    "id": "jZWMQ7sg09rE",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## MSE Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "do-gnv1u1HSI",
   "metadata": {
    "id": "do-gnv1u1HSI"
   },
   "source": [
    "Mean squared error (MSE) loss function is a non-convex function, i.e, it has more than one minimum, possibly many local minimum.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "MSE &=& \\frac{1}{N}\\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2.\n",
    "\\end{eqnarray}\n",
    "\n",
    "Legend:\n",
    "\n",
    "- $y_i$: ground truth value (label) for the $i$-th data point (sample).\n",
    "- $\\hat{y}_i$: predicted value for the $i$-th data point (sample).\n",
    "- $N$: the number of samples in a batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lNhb84W7rqKx",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1681068071009,
     "user": {
      "displayName": "Lucas Camponogara Viera",
      "userId": "14322290658374940800"
     },
     "user_tz": 180
    },
    "id": "lNhb84W7rqKx"
   },
   "outputs": [],
   "source": [
    "def mse(y_pred: np.ndarray, y_true: np.ndarray) -> np.float64:\n",
    "    '''\n",
    "    Calculates the Mean Squared Error (MSE) loss between the predicted and actual values.\n",
    "\n",
    "    Args:\n",
    "      - y_pred (numpy.ndarray): 2D array (num_samples, num_features) of predicted values.\n",
    "      - y_true (numpy.ndarray): 2D array (num_samples, num_features) of ground truth values.\n",
    "\n",
    "    Returns:\n",
    "      - loss (numpy.float64): mean squared error loss.\n",
    "    '''\n",
    "    err = y_pred - y_true\n",
    "    loss = np.mean(np.square(err))\n",
    "    return loss\n",
    "\n",
    "# Or equivalently:\n",
    "\n",
    "def mse2(y_pred, y_true, M):\n",
    "    err = y_pred - y_true\n",
    "    loss = np.sum(np.square(err))/M\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "yhIGAum3aC5q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1681068071009,
     "user": {
      "displayName": "Lucas Camponogara Viera",
      "userId": "14322290658374940800"
     },
     "user_tz": 180
    },
    "id": "yhIGAum3aC5q",
    "outputId": "98bacd2a-8e49-4434-819c-c56bbb5cf366"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.375, 0.375)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.array([3, -0.5, 2, 7], dtype=np.float32)\n",
    "y_true = np.array([2.5, 0.0, 2, 8], dtype=np.float32)\n",
    "\n",
    "mse(y_pred, y_true), mse2(y_pred, y_true, len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CdFUOteOh30l",
   "metadata": {
    "id": "CdFUOteOh30l"
   },
   "source": [
    "Check this result with [Keras API](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "JcS4MAq-6g6d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4691,
     "status": "ok",
     "timestamp": 1681068075693,
     "user": {
      "displayName": "Lucas Camponogara Viera",
      "userId": "14322290658374940800"
     },
     "user_tz": 180
    },
    "id": "JcS4MAq-6g6d",
    "outputId": "82299dc8-7530-4b22-c79a-449e76f5f5ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.375>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.losses.MSE(y_pred,y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a0196a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## MSE with L2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a55264f",
   "metadata": {},
   "source": [
    "\\begin{eqnarray}\n",
    "MSE_{L_2}  &=& \\text{MSE} + L_2 \\\\\n",
    "&=&  \\frac{1}{N}\\sum_{i=1}^{N} (y_i-\\hat{y}_i)^2 + \\lambda \\sum_{i=1}^L ||\\mathbf{W}^{(l)}||^2. \\\\\n",
    "&=&  \\frac{1}{N}\\sum_{i=1}^{N} (y_i-\\hat{y}_i)^2 + \\lambda \\sum_{i=1}^L \\sum_{j,k} \\mathbf{w}_{jk}^2. \\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "Legend:\n",
    "\n",
    "- $y_i$: ground truth value (label) for the $i$-th data point (sample).\n",
    "- $\\hat{y}_i$: predicted value for the $i$-th data point (sample).\n",
    "- $L$ is the number of weight matrices in the neural network.\n",
    "- $\\mathbf{w}_{jk}^{2}$ is the square value of the $j$-th weight for the $i$-th matrix.\n",
    "- $\\lambda$ is the regularization coefficient, a value between 0 and 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff9c2c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_l2(y_hat: np.ndarray, y_true: np.ndarray, weights: List[np.ndarray], regularization_coeff: float) -> np.float32:\n",
    "    '''\n",
    "    Calculates the Mean Squared Error (MSE) loss with L2 regularization between the predicted and actual values.\n",
    "\n",
    "    Args:\n",
    "      - y_hat (numpy.ndarray): 2D array (num_samples, num_features) of predicted values.\n",
    "      - y_true (numpy.ndarray): 2D array (num_samples, num_features) of ground truth values.\n",
    "      - weights (List[numpy.ndarray]): list of weight matrices in the network (including hidden layers and output layer).\n",
    "      - regularization_coeff (float): regularization coefficient for L2 regularization.\n",
    "\n",
    "    Returns:\n",
    "      - loss (numpy.float32): mean squared error loss with L2 regularization.\n",
    "    '''\n",
    "    err = y_hat - y_true\n",
    "    loss = np.mean(np.square(err))\n",
    "\n",
    "    regularization_term = 0.0\n",
    "    for weight_matrix in weights:\n",
    "        regularization_term += np.sum(np.square(weight_matrix))\n",
    "\n",
    "    loss += (regularization_coeff / 2) * regularization_term\n",
    "\n",
    "    return loss.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29f9fa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss with L2 Regularization: 0.047092877\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "\n",
    "y_hat = np.array([[0.8, 0.2], [0.6, 0.4]])  # Predicted values.\n",
    "y_true = np.array([[1.0, 0.0], [0.7, 0.3]]) # Ground truth values.\n",
    "weights = [np.random.rand(2, 4), np.random.rand(4, 2)] # Sample weight matrices.\n",
    "regularization_coeff = 0.01\n",
    "\n",
    "loss = mse_l2(y_hat, y_true, weights, regularization_coeff)\n",
    "print(\"MSE Loss with L2 Regularization:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QfTvr8YR7qyD",
   "metadata": {
    "id": "QfTvr8YR7qyD",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Binary Cross-Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t3b6EAw5J_5Z",
   "metadata": {
    "id": "t3b6EAw5J_5Z"
   },
   "source": [
    "The binary cross-entropy function measures the dissimilarity or information loss between the predicted probability and the true label of a single sample. It is used in classification tasks with only two classes.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "BCE \\equiv H(y, \\hat{y}) = - \\left( y \\cdot \\mathrm{log}\\; {\\hat{y}} + (1-y) \\cdot \\mathrm{log}\\; (1-{\\hat{y}}) \\right).\n",
    "\\end{eqnarray}\n",
    "\n",
    "Legend:\n",
    "\n",
    "- $log(x)$: is the natural logarithm of $x$.\n",
    "- $y$: is the actual label (ground truth value) of the sample. Either 0 (negative class) or 1 (positive class).\n",
    "- $\\hat{y}$: is the predicted probability for the positive class.\n",
    "- $(1-\\hat{y})$: is the predicted probability for the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90661b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(y_true: float, y_hat: float) -> float:\n",
    "    '''\n",
    "    Binary cross-entropy function.\n",
    "    \n",
    "    Args:\n",
    "        - y_true (float): actual label (ground truth value) of the sample. Either 0 or 1.\n",
    "        - y_hat (float): predicted probability for the positive class. A number between 0 and 1.\n",
    "    \n",
    "    Returns:\n",
    "        - bce (float): binary cross-entropy value.    \n",
    "    '''\n",
    "    bce = -(y_true * np.log(y_hat) + (1 - y_true) * np.log(1 - y_hat))\n",
    "    return bce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e7ca37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Cross-Entropy of one sample: 0.10536051565782628\n",
      "Mean Binary Cross-Entropy of two samples: 0.10536051565782628\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "    \n",
    "# One sample:\n",
    "print(\"Binary Cross-Entropy of one sample:\", binary_cross_entropy(0, 0.1))\n",
    "\n",
    "# Two samples:\n",
    "print(\"Mean Binary Cross-Entropy of two samples:\",(binary_cross_entropy(0, 0.1)+binary_cross_entropy(1, 0.9))/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac8c455",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Binary Cross-Entropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1044f5da",
   "metadata": {},
   "source": [
    "The binary cross-entropy loss function is the mean average of the binary cross entropy over a batch of data. \n",
    "\n",
    "\\begin{eqnarray}\n",
    "BCE_{loss} = \\frac{1}{N}\\sum_{i=1}^N BCE(y_i, \\hat{y}_i) = - \\frac{1}{N}\\sum_{i=1}^N y_i \\cdot \\mathrm{log}\\; {\\hat{y}}_i + (1-y_i) \\cdot \\mathrm{log}\\; (1-{\\hat{y}}_i).\n",
    "\\end{eqnarray}\n",
    "\n",
    "Legend:\n",
    "\n",
    "- $BCE(y_i, \\hat{y}_i)$: is the binary cross-entropy value of the $i$-th sample.\n",
    "- $y_i$: is the actual label (ground truth value) of the $i$-th sample. Either 0 (negative class) or 1 (positive class).\n",
    "- $\\hat{y}_i$: is the predicted probability for the positive class of the $i$-th sample.\n",
    "- $(1-\\hat{y}_i)$: is the predicted probability for the negative class of the $i$-th sample.\n",
    "- $N$: is the number of samples in a batch of data.\n",
    "\n",
    "In binary classification, the output layer of a neural network typically consists of a single neuron with sigmoid activation function or two neurons with softmax activation function. The value of each neuron in the output layer represents the predicted probability of a specific class.\n",
    "\n",
    "Note: the implementation **does not require target labels to be one-hot encoded**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wLdogFHX7yMW",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1681068075693,
     "user": {
      "displayName": "Lucas Camponogara Viera",
      "userId": "14322290658374940800"
     },
     "user_tz": 180
    },
    "id": "wLdogFHX7yMW"
   },
   "outputs": [],
   "source": [
    "def bce_loss1(y_true: np.ndarray or list, y_hat: np.ndarray or list) -> np.float32:\n",
    "    '''\n",
    "    Computes the binary cross-entropy loss function.\n",
    "    Uses list comprehension to iterate over the elements of y_true and y_hat and summing up the values.\n",
    "    \n",
    "    Args:\n",
    "      - y_true (numpy.ndarray or list): is the target array of true labels (ground truth probabilities).\n",
    "      - y_hat (numpy.ndarray or list): is the array of predicted probabilities.\n",
    "      \n",
    "    Returns:\n",
    "      - mean_loss (numpy.float32): binary cross-entropy loss. Mean average of the binary cross entropy.\n",
    "    '''\n",
    "    n_samples = len(y_true)\n",
    "    loss = -sum([(y_true[i]*np.log(y_hat[i])+(1-y_true[i])*np.log(1-y_hat[i])) for i in range(n_samples)])\n",
    "    mean_loss = loss/n_samples\n",
    "    return mean_loss.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbc930e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.105360515"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating arrays of two samples:\n",
    "y_true = [0, 1]\n",
    "y_pred = [0.1, 0.9]\n",
    "\n",
    "bce_loss1 = bce_loss1(y_true, y_pred)\n",
    "bce_loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caaff35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce_loss2(y_true: np.ndarray or list, y_hat: np.ndarray or list) -> np.float32:\n",
    "    '''\n",
    "    Computes the binary cross-entropy loss function.\n",
    "    Uses conditional statements.\n",
    "    \n",
    "    Args:\n",
    "      - y_true (numpy.ndarray): is the target array of true labels (ground truth probabilities).\n",
    "      - y_hat (numpy.ndarray): is the array of predicted probabilities.\n",
    "      \n",
    "    Returns:\n",
    "      - loss (numpy.float32): binary cross-entropy loss. Mean average of the binary cross entropy.\n",
    "    '''\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == 1:\n",
    "            return -np.log(y_hat[i]).astype(np.float32)\n",
    "        else:\n",
    "            return -np.log(1 - y_hat[i]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66cf2b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.105360515"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_loss2 = bce_loss2(y_true, y_pred)\n",
    "bce_loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2403447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce_loss3(y_true: np.ndarray, y_hat: np.ndarray) -> np.float32:\n",
    "    '''\n",
    "    Computes the binary cross-entropy loss function.\n",
    "    Uses NumPy's broadcasting to compute the cross-entropy loss for all input samples simultaneously.\n",
    "    \n",
    "    Args:\n",
    "      - y_true (numpy.ndarray): is the target array of true labels (ground truth probabilities).\n",
    "      - y_hat (numpy.ndarray): is the array of predicted probabilities.\n",
    "      \n",
    "    Returns:\n",
    "      - loss (numpy.float32): binary cross-entropy loss. Mean average of the binary cross entropy.\n",
    "    '''\n",
    "    loss = -np.mean(y_true * np.log(y_hat) + (1 - y_true) * np.log(1 - y_hat))\n",
    "    return loss.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04d1cba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2,), 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.array([0, 1])\n",
    "y_pred = np.array([0.1, 0.9])\n",
    "\n",
    "y_true.shape, y_true.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55445ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.105360515"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_loss3 = bce_loss3(y_true, y_pred)\n",
    "bce_loss3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48da108a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_loss1 == bce_loss2 == bce_loss3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DlsF_6ol770m",
   "metadata": {
    "id": "DlsF_6ol770m"
   },
   "source": [
    "[Check the result with Keras](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "izROEYm3gSiH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1681068075694,
     "user": {
      "displayName": "Lucas Camponogara Viera",
      "userId": "14322290658374940800"
     },
     "user_tz": 180
    },
    "id": "izROEYm3gSiH",
    "outputId": "0f5895dc-1c87-4ae5-f220-2191bea7cf77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1053604045467214"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_keras = tf.keras.losses.BinaryCrossentropy()\n",
    "bce_keras = bce_keras(y_true, y_pred).numpy()\n",
    "bce_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cc22900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10536, 0.10536)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing values up to 6 decimal places:\n",
    "round(bce_keras, 6), round(bce_loss2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I_nTfh0f1AX8",
   "metadata": {
    "id": "I_nTfh0f1AX8",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Categorical Cross-Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9u_TpjjL1Qo3",
   "metadata": {
    "id": "9u_TpjjL1Qo3"
   },
   "source": [
    "Categorical cross-entropy is a dissimilarity measure between predicted probability distributions and true labels. It is used in classification tasks with more than two classes.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "CCE &=& -\\sum_{i=1}^C y_i \\cdot \\mathrm{log}\\; (\\hat{y}_i).\n",
    "\\end{eqnarray}\n",
    "\n",
    "Legend:\n",
    "\n",
    "- $log(x)$: is the natural logarithm of $x$.\n",
    "- $y_i$: is the ground truth value corresponding to class $i$. Either 0 or 1.\n",
    "- $\\hat{y}_i$: is the predicted probability that observation (sample) $\\hat{O}$ is of class $i$.\n",
    "- $C$: number of classes.\n",
    "\n",
    "Upon expanding the sum, since there is only one non-zero label $y_i$, the equation can be further simplified to:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "CCE &=& - \\mathrm{log}\\; (\\hat{y}_c),\n",
    "\\end{eqnarray}\n",
    "\n",
    "where $\\hat{y}_c$ is the predicted probability for the correct class.\n",
    "\n",
    "Note: **target labels are required to be one-hot encoded**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f30272b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3,), 3, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating array of one sample and three classes:\n",
    "y_true = np.array([0, 1, 0]) # One-hot encoding.\n",
    "y_pred = np.array([0.05, 0.94, 0.01])\n",
    "\n",
    "y_true.shape, y_true.size, y_true.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fef7b028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_cross_entropy(y_true: np.ndarray, y_hat: np.ndarray) -> np.float32:\n",
    "    '''\n",
    "    Computes the categorical cross-entropy function.\n",
    "    \n",
    "    Args:\n",
    "      - y_true (numpy.ndarray): the one-hot encoded target array of true labels (ground truth probabilities).\n",
    "      - y_hat (numpy.ndarray): the array of predicted probabilities.\n",
    "    \n",
    "    Returns:\n",
    "      - cce (numpy.float32): categorical cross-entropy value.    \n",
    "    '''\n",
    "    eps = 1e-15 # Add a small value to y_hat to avoid taking the logarithm of zero.\n",
    "    cce = -np.sum(y_true * np.log(y_hat + eps))\n",
    "    return cce.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02473f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical cross-entropy with three classes: 0.061875403\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "\n",
    "print(\"Categorical cross-entropy with three classes:\", categorical_cross_entropy(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6961f243",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Categorical Cross-Entropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e5f773",
   "metadata": {},
   "source": [
    "The categorical cross-entropy loss is the mean average of the categorical cross-entropy function over a batch of data. \n",
    "\n",
    "\\begin{eqnarray}\n",
    "CCE_{loss} &=& -\\frac{1}{N}\\sum_{i=1}^N (CCE)_i.\n",
    "\\end{eqnarray}\n",
    "\n",
    "Legend:\n",
    "\n",
    "- $(CCE)_i$: categorical cross-entropy value of the $i$-th sample.\n",
    "- $N$: the number of samples in a batch of data.\n",
    "\n",
    "In multi-class classification, the output layer of a neural network has as many neurons as there are classes and the activation function is typically softmax. The value of each neuron in the output layer represents the predicted probability of a specific class. **Target labels are required to be one-hot encoded**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "992d6989",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 3), 6, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating array of two samples and three classes:\n",
    "y_true = np.array([[0, 1, 0], [0, 0, 1]]) # One-hot encoding.\n",
    "y_pred = np.array([[0.05, 0.94, 0.01], [0.1, 0.8, 0.1]])\n",
    "\n",
    "y_true.shape, y_true.size, y_true.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0536c7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cce_loss1(y_true: np.ndarray, y_hat: np.ndarray) -> np.float32:\n",
    "    '''\n",
    "    Computes the multi-class (categorical) cross-entropy loss function.\n",
    "    Uses NumPy's broadcasting to compute the cross-entropy loss for all input examples simultaneously.\n",
    "    \n",
    "    Args:\n",
    "      - y_true (numpy.ndarray): 2D target array of true labels (ground truth probabilities).\n",
    "      - y_hat (numpy.ndarray): 2D array of predicted probabilities.\n",
    "      \n",
    "    Returns:\n",
    "      - loss (numpy.float32): categorical cross-entropy loss value.\n",
    "    '''\n",
    "    eps = 1e-15 # Add a small value to y_hat to avoid taking the logarithm of zero.\n",
    "    #y_hat = np.clip(y_hat, eps, 1 - eps) # Clip y_hat to the range [epsilon, 1 - epsilon].\n",
    "    #n_samples = y_true.shape[0]\n",
    "    #loss = -np.sum(y_true * np.log(y_hat)) / n_samples\n",
    "    loss = -np.mean(np.sum(y_true * np.log(y_hat + eps), axis=1))\n",
    "    return loss.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1e66445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical cross-entropy loss for two samples and three classes: 1.1822302\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "\n",
    "cce_loss1 = cce_loss1(y_true, y_pred)\n",
    "print(\"Categorical cross-entropy loss for two samples and three classes:\", cce_loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "650fbecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case passed!\n"
     ]
    }
   ],
   "source": [
    "mean_cce = (categorical_cross_entropy(y_true[0], y_pred[0])+categorical_cross_entropy(y_true[1], y_pred[1]))/2\n",
    "mean_cce = mean_cce.astype(np.float32)\n",
    "\n",
    "assert cce_loss1 == mean_cce, \"Test case failed.\"\n",
    "print(\"Test case passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "JWrl4_VM1Bo6",
   "metadata": {
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1681068076081,
     "user": {
      "displayName": "Lucas Camponogara Viera",
      "userId": "14322290658374940800"
     },
     "user_tz": 180
    },
    "id": "JWrl4_VM1Bo6"
   },
   "outputs": [],
   "source": [
    "def cce_loss2(y_true: np.ndarray, y_hat: np.ndarray) -> np.float32:\n",
    "    '''\n",
    "    Computes the multi-class (categorical) cross-entropy loss function.\n",
    "    Uses list comprehension.\n",
    "\n",
    "    Args:\n",
    "      - y_true (numpy.ndarray): target array of true labels (ground truth probabilities).\n",
    "      - y_hat (numpy.ndarray): array of predicted probabilities.\n",
    "      \n",
    "    Returns:\n",
    "      - loss (numpy.float32): categorical cross-entropy loss value. Mean average of categorical cross-entropy.\n",
    "    '''\n",
    "    eps = 1e-15 # Add a small value to y_hat to avoid taking the logarithm of zero.\n",
    "    loss = np.mean([-np.sum(y_true[i]*np.log(y_hat[i] + eps)) for i in range(len(y_true))])\n",
    "    return loss.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "247ed20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical cross-entropy loss for two samples and three classes: 1.1822302\n"
     ]
    }
   ],
   "source": [
    "cce_loss2 = cce_loss2(y_true, y_pred)\n",
    "print(\"Categorical cross-entropy loss for two samples and three classes:\", cce_loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14028b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing values up to 7 decimal places:\n",
    "round(cce_loss1, 7) == round(cce_loss2, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x_J6_O_l1xYd",
   "metadata": {
    "id": "x_J6_O_l1xYd"
   },
   "source": [
    "[Checking the result with tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "h5MY7Y3r0aaF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1681068076410,
     "user": {
      "displayName": "Lucas Camponogara Viera",
      "userId": "14322290658374940800"
     },
     "user_tz": 180
    },
    "id": "h5MY7Y3r0aaF",
    "outputId": "81121927-f2a0-488b-a04a-e90e87d6f1d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1822302"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [1, 2] # Label encoding.\n",
    "y_pred = [[0.05, 0.94, 0.01], [0.1, 0.8, 0.1]]\n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "scce = scce(y_true, y_pred).numpy()\n",
    "scce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d4Jrz_h56kO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1681068076410,
     "user": {
      "displayName": "Lucas Camponogara Viera",
      "userId": "14322290658374940800"
     },
     "user_tz": 180
    },
    "id": "0d4Jrz_h56kO",
    "outputId": "fe3410fc-4460-46fc-a3ce-557a8bb38ec8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1822302"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "los = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "y_true = np.array([[0, 1, 0], [0, 0, 1]]) # One-hot encoding.\n",
    "y_pred = np.array([[0.05, 0.94, 0.01], [0.1, 0.8, 0.1]])\n",
    "\n",
    "cce_keras = tf.keras.losses.CategoricalCrossentropy() \n",
    "cce_keras = cce_keras(y_true, y_pred).numpy().astype(np.float32)\n",
    "cce_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1089fb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scce == cce_keras == cce_loss1 == cce_loss2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda8c31c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sparse Categorical Cross-Entropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30e4558",
   "metadata": {},
   "source": [
    "This loss is specifically designed for scenarios where the target labels are integers rather than one-hot encoded vectors. When using this loss in keras, there is no need to use a Dense layer with a softmax activation as the output layer. Keras will handle internally the conversion of logits to probabilities during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3ce6ac",
   "metadata": {},
   "source": [
    "```python\n",
    "model = keras.Sequential()\n",
    "model.add(...)\n",
    "model.add(Dense(nr_of_classes))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad71d31",
   "metadata": {
    "id": "7ad71d31",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# <font color='orange'> Backpropagation </font><a name=\"Implementation\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d726df9",
   "metadata": {},
   "source": [
    "See the following resource for a visualization of the backpropagation algorithm:\n",
    "    \n",
    "1. [3Blue1Brown](https://www.youtube.com/watch?v=tIeHLnjs5U8)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a68c8a1",
   "metadata": {
    "id": "8a68c8a1"
   },
   "source": [
    "- Gradient descent: is an **optimizer** whose objective is to update the weights of the neural network in order to minimize the value of the loss function. To do so it calculates the gradient of the loss function w.r.t the weights via an algorithm called backpropagation. This gradient is a vector where each component of the vector is the derivative of the loss ($\\mathcal{L}$) with respect to the weights ($w_{kj}$) and biases ($b_j$).\n",
    "<br>\n",
    "\n",
    "- Backpropagation: is the computation of the chain rule¹ of calculus used to calculate the gradient of the loss function starting from the output layer and going backwards to the input layer. It uses the chain rule because the loss function depends of the output activation function which in turn depends on the previous activations and weights, i.e, a composition of functions.\n",
    "<br>\n",
    "\n",
    "- In SGD, as the size of the parameter vector we are trying to optimize gets larger (like a million), any local minima is as good as a global minima. Ps: I heard that in a keynote from David Silver, and I agree.\n",
    "\n",
    "**Note:** there are several other optimizers available to replace gradient descent, such as Adam, AdaGrad, Adadelta and RMSProp, to name a few.\n",
    "\n",
    "---\n",
    "¹Chain rule is the derivative of the composition of two or more functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e9fd5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Neural Network Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c444d374",
   "metadata": {},
   "source": [
    "**Definitions:**\n",
    "\n",
    "- $\\hat{y}$: predicted value.\n",
    "- $y$: ground truth.\n",
    "- $y_j$: the ground truth value (expected value) of node $j$ in a hidden layer $l$. Is a parameter (a constant value).\n",
    "- NN: short for \"Neural Network\".\n",
    "- $L$: total number of layers in the NN.\n",
    "- $N$: total number of neurons (a.k.a nodes) in a given layer.\n",
    "- $l (l= 1, 2, 3, \\cdots, L-1)$: index of the nth-hidden layer in the NN.\n",
    "- $j (j=0,1,2, \\cdots, N-1)$: index for nodes in a hidden layer.\n",
    "- $k (k=0,1,2, \\cdots, N-1)$: index for nodes in the output layer $L$.\n",
    "- $\\mathcal{L}$: loss function of the output layer $L$.\n",
    "- $w_{i\\rightarrow j}$: is the matrix of weights (sinapses) that connects the output of neuron $n_i$ in layer $l-1$ to the input of neuron $n_j$ in layer $l$.\n",
    "- $w_{j}^l$: vector containing all the weights connected to node $j$ in layer $l$ by each node in the previous layer indexed by $l-1$. This is a fully connected NN.\n",
    "- $s_{j}^{(l)}$: input of node $j$ in layer $l$.\n",
    "- $g^{(l)}$: activation function of layer $l$. There is one activation function for each neuron. A given layer has the same activation function for all of its neurons.\n",
    "- $z_j^{(l)}$: activation output of node $j$ in layer $l$. \n",
    "- $b_j$: bias for each node in layer $l$.\n",
    "\n",
    "How to read $a_j^{(l)}$: \"$a$ sub $j$ superscript $l$\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa4c78b",
   "metadata": {},
   "source": [
    "**Dense (fully connected) layers have the following algebra:**\n",
    "\n",
    "Input of node $j$ in layer $l$ is given by a weighted sum:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "s_j^{(l)} = \\sum_{i=0}^{N-1} w_{i \\rightarrow j}^l z_i^{(l-1)}+b_j^{(l)}.\n",
    "\\end{eqnarray}\n",
    "\n",
    "Activation output of node $j$ in layer $l$:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "z_j^{(l)} = g^{(l)}(s_j^{(l)}) = g^{(l)}\\left(\\sum_{i=0}^{N-1} w_{i\\rightarrow j}^l z_i^{(l-1)}+b_j^{(l)}\\right).\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb02621e-35e7-4874-b01e-5906c127eb9a",
   "metadata": {},
   "source": [
    "| Convention     | Activation Shape     | Weight Shape                   | Formula                                                         \n",
    "|----------------|----------------------|--------------------------------|-----------------------------\n",
    "| Column vector  | `(n × 1)`            | `(n_out × n)`                  | $s_j^{(l)} = w_{i \\rightarrow j}^l z_i^{(l-1)}+b_j^{(l)}$\n",
    "| Row vector     | `(1 × n)`            | `(n × n_out)`                  | $s_j^{(l)} = z_i^{(l-1)} w_{i \\rightarrow j}^l + b_j^{(l)}$\n",
    "\n",
    "Where `n` and `n_out` are the number of input and output neurons in the weight matrix of the $l$-th layer, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b13f2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## The backpropagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595e23ff",
   "metadata": {},
   "source": [
    "- Step 1. Use the chain rule to compute the gradient of the loss function which is a composite function of activations and weights.\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial(\\text{loss})}{\\partial (\\text{weight})} = \\frac{\\partial \\mathcal{L}(z_k(s_k(w_k)))}{\\partial w_{j\\rightarrow k}^{(l)}} = \\frac{\\partial \\mathcal{L}}{\\partial z_k^{(l)}}\\frac{\\partial z_k^{(l)}}{\\partial s_k^{(l)}}\\frac{\\partial s_k^{(l)}}{\\partial w_{j\\rightarrow k}^{(l)}}.\n",
    "\\end{align*}\n",
    "\n",
    "By definition of the weighted sum, the last term is:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial s_k}{\\partial w_{j\\rightarrow k}^{(l)}} = \\frac{\\partial}{\\partial w_{j\\rightarrow k}^{(l)}}\\left(\\sum_{j=0}^{N-1} w_{j \\rightarrow k}^{(l)} z_j^{(l-1)}+b_k^{(L)} \\right) = z_j^{(l-1)} \\frac{\\partial}{\\partial w_{j\\rightarrow k}^{(l)}} \\sum_{j=0}^{N-1} w_{j \\rightarrow k}^{(l)} = z_j^{(l-1)}.\n",
    "\\end{align*}\n",
    "\n",
    "With that:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}(z_k(s_k(w_k)))}{\\partial w_{j\\rightarrow k}^{(l)}} =  \\left(\\frac{\\partial \\mathcal{L}}{\\partial z_k^{(l)}}\\frac{\\partial z_k^{(l)}}{\\partial s_k^{(l)}} \\right) z_k^{(l-1)} := \\delta_k^{(l)} \\cdot z_j^{(l-1)}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addfd1a5",
   "metadata": {},
   "source": [
    "- Step 1.1 Compute $\\delta_k$ for node $k$ in output layer $L$:\n",
    "\n",
    "$$\\delta_k = \\left(\\frac{\\partial \\mathcal{L}}{\\partial z_{k}^{(L)}}\\right)\\left(\\frac{\\partial z_k^{(L)}}{\\partial s_{k}^{(L)}}\\right).$$\n",
    "\n",
    "- Step 1.2 Compute $\\delta_j$ for node $j$ in hidden layer $l$:\n",
    "\n",
    "$$\\delta_j = \\left(\\frac{\\partial \\mathcal{L}}{\\partial z_j^{(l)}}\\frac{\\partial z_j^{(l)}}{\\partial s_j^{(l)}} \\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cc724b",
   "metadata": {},
   "source": [
    "- Step 2. Update weights via Gradient Descent (GD) with learning rate $\\eta$:\n",
    "\n",
    "$$w_{j+1} = w_j - \\eta \\frac{\\partial \\mathcal{L}}{\\partial w_{i\\rightarrow j}^{(l)}} = w_j - \\eta (\\delta_j^l \\cdot z_j^{(l-1)}).$$\n",
    "\n",
    "- Step 3. Update biases via Gradient Descent (GD) with learning rate $\\eta$:\n",
    "\n",
    "$$b_{j+1} = b_j -  \\eta \\frac{\\partial \\mathcal{L}}{\\partial b_{j}^{(l)}} = b_j - \\eta \\delta_j^l.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d650e03e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Backpropagation for MSE loss and Sigmoid activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b147761",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Computing the gradient for node $k$ in output layer $L$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5242fee7",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial \\mathcal{L}(z_k(s_k(w_k)))}{\\partial w_{j\\rightarrow k}} = \\underbrace{\\Big(\\frac{\\partial \\mathcal{L}}{\\partial z_k}\\frac{\\partial z_k}{\\partial s_k}\\Big)}_{\\delta_k}  \\frac{\\partial s_k}{\\partial w_{j\\rightarrow k}} = \\delta_k^{(L)} \\cdot z_k^{(L-1)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ef538d",
   "metadata": {},
   "source": [
    "- The first term of $\\delta_k$ is:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial z_k} =\\frac{\\partial}{\\partial z_k} \\left(\\frac{1}{2}\\sum_{k \\in L=1}^{2} (z_k-y_k)^2 \\right)= (z_k - y_k).$$\n",
    "\n",
    "To see why, expand the series:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial z_{1}} =  \\frac{\\partial}{\\partial z_1}\\frac{\\left(\\sum_{j=0}^{n} (z_j - y_j)^2 \\right)}{2}= \\frac{\\partial}{\\partial z_1}\\frac{(z_0 -y_0)^2}{2}+\\frac{\\partial}{\\partial z_1}\\frac{(z_1 -y_1)^2}{2}+\\cdots +\\frac{\\partial}{\\partial z_1}\\frac{(z_n -y_n)^2}{2}= (z_1 -y_1).\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a16f04",
   "metadata": {},
   "source": [
    "- The second term of $\\delta_k$ is:\n",
    "\n",
    "$$\\frac{\\partial z_k}{\\partial s_k} = \\frac{\\partial}{\\partial s_k} (\\sigma (s_k)) = \\frac{\\partial}{\\partial s_k} \\Bigg(\\frac{1}{1+e^{-s_k}}\\Bigg).$$\n",
    "\n",
    "Using the chain rule of calculus\n",
    "\n",
    "$$\\frac{d}{dx}\\left(f(g(x))\\right) = f'(g(x)) \\cdot g'(x),$$\n",
    "\n",
    "the Sigmoid derivative is\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial}{\\partial x} \\Bigg(\\frac{1}{1+e^{-x}}\\Bigg) &= \\frac{\\partial}{\\partial x} \\Big(1+e^{-x}\\Big)^{-1}\\\\ \n",
    "&= -\\Big(1+e^{-x}\\Big)^{-2} \\cdot \\frac{\\partial}{\\partial x} \\Big (1+e^{-x}\\Big) \\\\\n",
    "&=-\\Big(1+e^{-x}\\Big)^{-2} \\cdot (- e^{-x})\\\\\n",
    "&= e^{-x}\\Big(1+e^{-x}\\Big)^{-2} \\\\\n",
    "&= \\frac{1}{1+e^{-x}}\\frac{e^{-x}}{1+e^{-x}}\\\\\n",
    "&= \\frac{1}{1+e^{-x}}\\frac{1+e^{-x}-1}{1+e^{-x}}\\\\\n",
    "&= \\frac{1}{1+e^{-x}}\\Bigg(\\frac{1+e^{-x}}{1+e^{-x}}-\\frac{1}{1+e^{-x}}\\Bigg)\\\\\n",
    "&=\\sigma(x) (1-\\sigma(x)).\n",
    "\\end{align} \n",
    "\n",
    "One then has\n",
    "\n",
    "$$\\frac{\\partial z_k^{(L)}}{\\partial s_k} = \\frac{\\partial}{\\partial s_k} (\\sigma (s_k^{(L)})) = \\sigma(s_k) (1-\\sigma(s_k))= z_k(1-z_k).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1262b943",
   "metadata": {},
   "source": [
    "**The complete gradient for the output layer thus becomes:**\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}(z_k(s_k(w_k)))}{\\partial w_{j\\rightarrow k}} = \\delta_k^{(L)} z_k^{(L-1)} = (z_k^{(L)} - y_k)z_k^{(L)}(1-z_k^{(L)})z_k^{(L-1)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f89466c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Computing the gradient for the hidden layers\n",
    "\n",
    "The following math takes in consideration that `Sigmoid` is also used in the hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ecd68d",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial \\mathcal{L}(z_j(s_j(w_j)))}{\\partial w_{i\\rightarrow j}^{(L-1)}} = \\underbrace{\\Big(\\frac{\\partial \\mathcal{L}}{\\partial z_j^{(L-1)}}\\frac{\\partial z_j^{(L-1)}}{\\partial s_j^{(L-1)}}\\Big)}_{\\delta_j}  \\frac{\\partial s_j^{(L-1)}}{\\partial w_{i\\rightarrow j}^{(L-1)}} = \\delta_j^{l} \\cdot z_j^{(l-1)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0525deb7",
   "metadata": {},
   "source": [
    "One can see that the only difference here is the index changed, $k \\rightarrow j$, as we backpropagate from a node $n_k$ in the output layer $L$ to a node $n_j$ in the hidden layer $L-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c22cbf",
   "metadata": {},
   "source": [
    "- The first term of $\\delta_j$ is (for an arbitrary layer $l$):\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial z_j^{(L-1)}} =  \\sum_{k \\in l=1}^N \\frac{\\partial \\mathcal{L}}{\\partial z_k}\\frac{\\partial z_k}{\\partial s_k}\\frac{\\partial s_k}{\\partial z_j} :=  \\sum_{k \\in l=1}^N  \\delta_k \\frac{\\partial s_k}{\\partial z_j}.\n",
    "\\end{align*}\n",
    "\n",
    "With\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial s_k}{\\partial z_j} = \\frac{\\partial}{\\partial z_j} \\left(\\sum_{j=0}^{N-1} w_{j \\rightarrow k}^{(l)} z_j^{(l-1)}+b_k \\right) = \n",
    " w_{j \\rightarrow k}^{(l)} \\cdot \\sum_{j=0}^{N-1} \\frac{\\partial}{\\partial z_j} (z_j^{(l-1)}) = w_{j \\rightarrow k}^{(l)}.\n",
    "\\end{align*}\n",
    "\n",
    "Then\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial z_j^{(L-1)}} =  \\sum_{k \\in L=1}^N \\delta_k^{(L)} w_{j\\rightarrow k}^{(L)}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638d549e",
   "metadata": {},
   "source": [
    "- The second term of $\\delta_j$ is (as before):\n",
    "\n",
    "$$\\frac{\\partial z_j^{(L-1)}}{\\partial s_j} = \\frac{\\partial}{\\partial s_j} (\\sigma (s_j)) = \\frac{\\partial}{\\partial s_j} \\Bigg(\\frac{1}{1+e^{-s_j}}\\Bigg) =  z_j(1-z_j).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a20e645",
   "metadata": {},
   "source": [
    "**The complete gradient for the hidden layer thus becomes:**\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}(z_j(s_j(w_j)))}{\\partial w_{i\\rightarrow j}} = \\underbrace{\\Big(\\frac{\\partial \\mathcal{L}}{\\partial z_j}\\Big)}_\\text{1st term} \\Big( \\frac{\\partial z_j}{\\partial s_j}\\Big) \\Big(\\frac{\\partial s_j}{\\partial w_{i\\rightarrow j}}\\Big)=\\delta_j^{(l)} z_j^{(l-1)}=\\underbrace{\\left(\\sum_{k \\in l=1}^N \\delta_k^{(l+1)} w_{j\\rightarrow k}\\right)}_\\text{1st term} \\left(z_{j}^{(l)}(1-z_{j}^{(l)}) \\right)z_j^{(l-1)}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4613ceae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad47242f",
   "metadata": {},
   "source": [
    "- Output layer:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}(z_k(s_k(w_k)))}{\\partial w_{j\\rightarrow k}} = \\delta_k z_k^{(l-1)} = (z_k - y_k)z_k(1-z_k)z_k^{(l-1)}.$$\n",
    "\n",
    "- Hdden layer:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}(z_j(s_j(w_j)))}{\\partial w_{i\\rightarrow j}} =\\delta_j z_j^{(l-1)}=\\left(\\sum_{k \\in l=1}^N \\delta_k^{(l+1)} w_{j\\rightarrow k}\\right) z_{j}^{(l)}(1-z_{j}^{(l)})z_j^{(l-1)}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192883d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Backpropagation for Categorical Cross-Entropy loss and Softmax activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002e4ed1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Computing the gradient for node $k$ in output layer $L$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22a5af1",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial \\mathcal{L}(z_k(s_k(w_k)))}{\\partial w_{j\\rightarrow k}} = \\underbrace{\\Big(\\frac{\\partial \\mathcal{L}}{\\partial z_k}\\frac{\\partial z_k}{\\partial s_k}\\Big)}_{\\delta_k}  \\frac{\\partial s_k}{\\partial w_{j\\rightarrow k}} = \\delta_k^{(L)} z_k^{(L-1)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19f9bb8",
   "metadata": {},
   "source": [
    "- The first term of $\\delta_k$ is:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial z_k} &= \\frac{\\partial}{\\partial  z_k}\\left(-\\sum_{i=1}^N y_i \\cdot \\mathrm{log}\\ (z_i)\\right) =  - \\sum_{i=1}^N y_i \\frac{\\partial}{\\partial z_k} \\mathrm{log}(z_i) = - \\sum_{i=1}^N y_i \\frac{\\partial (\\mathrm{log}(z_i))}{\\partial z_i} \\frac{\\partial z_i}{\\partial z_k} \\delta_{ik} =  - \\sum_{i=1}^N y_i \\frac{1}{z_i} \\frac{\\partial z_i}{\\partial z_k}\\delta_{ik} = - \\sum_{k=1}^N \\frac{y_k}{z_k}.\n",
    "\\end{align*}\n",
    "\n",
    "Where $\\delta_{ik}$ is the [Kronecker delta](https://en.wikipedia.org/wiki/Kronecker_delta) used to impose $i=k$ (a.k.a contraction), otherwise the result would be zero. Since due to the summation, at least one element from the derivative is different than zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edc2a2b",
   "metadata": {},
   "source": [
    "- The second term of $\\delta_k$ is:\n",
    "\n",
    "$$\\frac{\\partial z_k^{(L)}}{\\partial s_k} = \\frac{\\partial}{\\partial s_k} (\\sigma (s_k^{(L)})) = \\frac{\\partial}{\\partial s_k} \\Bigg(\\frac{e^{s_k}}{\\sum_i e^{s_i}}\\Bigg).$$\n",
    "\n",
    "Recall the quotient rule of Calculus for derivatives:\n",
    "\n",
    "$$\\frac{d}{dx}\\left(\\frac{f(x)}{g(x)}\\right) = \\frac{g(x) \\cdot f'(x) - f(x) \\cdot g'(x)}{[g(x)]^2}.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ba2186",
   "metadata": {},
   "source": [
    "Since all possible combinations need to be evaluated, one takes the derivative w.r.t a different index. \n",
    "\n",
    "For the numerator (using the chain rule):\n",
    "\n",
    "\\begin{equation}\n",
    "f'(x) = \\frac{\\partial}{\\partial s_j} (e^{s_k}) = \\frac{\\partial (e^{s_k})}{\\partial s_k} \\cdot \\frac{\\partial (s_k)}{\\partial s_j} = e^{s_k} \\frac{\\partial s_k}{\\partial s_k} \\cdot \\frac{\\partial (s_k)}{\\partial s_j} = \n",
    "\\begin{cases}\n",
    "e^{s_k} &\\text{if } k=j, \\\\\n",
    "0 &\\text{if } k \\ne j.\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "For the denominator:\n",
    "\n",
    "\\begin{equation}\n",
    "g'(x) = \\frac{\\partial}{\\partial s_j} \\Big(\\sum_{i=1}^n e^{s_i}\\Big) = e^{s_i}\\delta_{ij} =  e^{s_j}. \n",
    "\\end{equation}\n",
    "\n",
    "Again, because of the summation, Kronecker delta can be used to indicate that the derivative is non-zero only when the indices match."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178116ea",
   "metadata": {},
   "source": [
    "**The Softmax derivative for $k=j$:**\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial}{\\partial s_j} \\Bigg(\\frac{e^{s_k}}{\\sum_i{e^{s_i}}}\\Bigg) &= \\frac{(\\sum_i{e^{s_i}})e^{s_k}-e^{s_k} e^{s_j}}{(\\sum_i{e^{s_i}})^2} = \\frac{e^{s_k}}{\\sum_i{e^{s_i}}}\\Bigg(1-\\frac{e^{s_j}}{\\sum_i{e^{s_i}}} \\Bigg) \\delta_{jk}\n",
    "= softmax(s_k)\\Bigg(1-softmax(s_k)\\Bigg) = z_k(1-z_k).\n",
    "\\end{align} \n",
    "\n",
    "**The Softmax derivative for $k \\ne j$:**\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial}{\\partial s_j} \\Bigg(\\frac{e^{s_k}}{\\sum_i{e^{s_i}}}\\Bigg) &= \n",
    "\\frac{0-e^{s_k}e^{s_j}}{(\\sum_i{e^{s_i}})^2}= -\\frac{e^{s_k}}{\\sum_i{e^{s_i}}}\\frac{e^{s_j}}{\\sum_i{e^{s_i}}}=-softmax(s_k)\\cdot softmax(s_j) = -z_kz_j.\n",
    "\\end{align} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14505f2c",
   "metadata": {},
   "source": [
    "Combining both cases, one then gets:\n",
    "    \n",
    "\\begin{eqnarray}\n",
    "\\delta_k^{(L)} = \\Big(\\frac{\\partial \\mathcal{L}}{\\partial z_k}\\frac{\\partial z_k}{\\partial s_j}\\Big) \n",
    "&=& - \\sum_{k=1}^N \\frac{y_k}{z_k} \\frac{\\partial z_k}{\\partial s_j} \\\\\n",
    "&=& - \\sum_{k=1}^N \\frac{y_k}{z_k} z_j (\\delta_{kj} - z_k)\\\\\n",
    "&=& - \\sum_{k=1}^N \\frac{y_k}{z_k} z_k(1-z_k) - \\sum_{j=1, j\\ne k}^N  \\frac{y_j}{z_j}  \\Big(-z_j z_k\\Big) \\\\\n",
    "&=& - \\frac{y_k}{z_k} z_k(1-z_k) - \\sum_{j=1, j\\ne k}^N  \\frac{y_j}{z_j}  \\Big(-z_j z_k\\Big) \\\\\n",
    "&=& - y_k+y_k z_k+\\sum_{j=1, j\\ne k}^N y_j z_k \\\\\n",
    "&=& - y_k + z_k\\Big(y_k + \\sum_{j=1, j\\ne k}^N y_j \\Big)\\\\\n",
    "&=& - y_k + z_k \\underbrace{\\Big(\\sum_{j=1}^N y_j \\Big)}_\\text{=1}\\\\\n",
    "&=& - y_k + z_k = z_k - y_k.\n",
    "\\end{eqnarray}\n",
    "\n",
    "Recall that $y_k$ is the ground truth probability distribution and, therefore, it adds up to one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed66398b",
   "metadata": {},
   "source": [
    "**The complete gradient for the output layer thus becomes:**\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}(z_k(s_k(w_k)))}{\\partial w_{j\\rightarrow k}} = \\delta_k^{(L)} z_k^{(L-1)} = (z_k^{(L)}-y_k) z_k^{(L-1)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e3aade",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Computing the gradient for the hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d8fa77",
   "metadata": {},
   "source": [
    "- **First approach:**\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}(z_j(s_j(w_j)))}{\\partial w_{i\\rightarrow j}^{(l-1)}} = \\underbrace{\\Big(\\frac{\\partial \\mathcal{L}}{\\partial z_j^{(l-1)}}\\frac{\\partial z_j^{(l-1)}}{\\partial s_j^{(l-1)}}\\Big)}_{\\delta_j}  \\frac{\\partial s_j^{(l-1)}}{\\partial w_{i\\rightarrow j}^{(l-1)}} = \\delta_j^{l} \\cdot z_j^{(l-1)}.$$\n",
    "\n",
    "The first term of $\\delta_j$ (for an arbitrary layer $l$) is :\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial z_j^{(l-1)}} =  \\sum_{k \\in l=1}^N \\Big(\\frac{\\partial \\mathcal{L}}{\\partial z_k}\\frac{\\partial z_k}{\\partial s_k}\\Big)\\frac{\\partial s_k}{\\partial z_j} =  \\sum_{k \\in l=1}^N  (z_k^{(l)}-y_k) \\frac{\\partial s_k}{\\partial z_j}.\n",
    "\\end{align*}\n",
    "\n",
    "With\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial s_k}{\\partial z_j} = \\frac{\\partial}{\\partial z_j} \\left(\\sum_{j=0}^{N-1} w_{j \\rightarrow k} z_j^{(l-1)}+b_k \\right) = \n",
    " w_{j \\rightarrow k}^{(l)} \\cdot \\sum_{j=0}^{N-1} \\frac{\\partial}{\\partial z_j} (z_j^{(l-1)}) = w_{j \\rightarrow k}.\n",
    "\\end{align*}\n",
    "\n",
    "Hence,\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial z_j^{(l-1)}} =  \\sum_{k \\in L=1}^N (z_k^{(l)}-y_k) w_{j\\rightarrow k}.\n",
    "\\end{align*}\n",
    "\n",
    "The second term of $\\delta_j$ is:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial z_j^{(l-1)}}{\\partial s_j^{(l-1)}} = \\sigma'(s_j^{(l-1)}).\n",
    "\\end{align*}\n",
    "\n",
    "Finally, \n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}(z_j(s_j(w_j)))}{\\partial w_{i\\rightarrow j}^{(l-1)}} =  \\sum_{k \\in l=1}^N (z_k^{(l)}-y_k) w_{j\\rightarrow k} \\sigma'(s_j^{(l-1)})z_{j}^{(l-2)}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a902ea97",
   "metadata": {},
   "source": [
    "- **Second approach:**\n",
    "\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}(z_j(s_j(w_j)))}{\\partial w_{i\\rightarrow j}^{(l-1)}} = \\frac{\\partial \\mathcal{L}}{\\partial s_j^{(l-1)}} \\frac{\\partial s_j^{(l-1)}}{\\partial w_{i\\rightarrow j}^{(l-1)}} = \\frac{\\partial \\mathcal{L}}{\\partial s_j^{(l-1)}} z_{j}^{(l-2)}.$$\n",
    "\n",
    "The first term has the following chain rule:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial s_j^{(l-1)}} =  \\sum_{k \\in l=1}^N \\frac{\\partial \\mathcal{L}}{\\partial s_k^{(l)}}\\frac{\\partial s_k^{(l)}}{\\partial z_j^{(l-1)}}\\frac{\\partial z_j^{(l-1)}}{\\partial s_j^{(l-1)}}.\n",
    "\\end{align*}\n",
    "\n",
    "Where:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial s_k^{(l)}} = \\Big(\\frac{\\partial \\mathcal{L}}{\\partial z_j}\\frac{\\partial z_j}{\\partial s_k}\\Big)  = z_k^{(l)}-y_k.\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial s_k^{(l)}}{\\partial z_j^{(l-1)}} = \\frac{\\partial}{\\partial z_j^{(l-1)}} \\left(\\sum_{j=0}^{N-1} w_{j \\rightarrow k}^{(l)} z_j^{(l-1)}+b_k \\right) = \n",
    " w_{j \\rightarrow k}^{(l)} \\cdot \\sum_{j=0}^{N-1} \\frac{\\partial}{\\partial z_j^{(l-1)}} (z_j^{(l-1)}) = w_{j \\rightarrow k}^{(l)}.\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial z_j^{(l-1)}}{\\partial s_j^{(l-1)}} = \\sigma'(s_j^{(l-1)}).\n",
    "\\end{align*}\n",
    "\n",
    "Finally, \n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}(z_j(s_j(w_j)))}{\\partial w_{i\\rightarrow j}^{(l-1)}} =  \\sum_{k \\in l=1}^N (z_k^{(l)}-y_k) w_{j\\rightarrow k} \\sigma'(s_j^{(l-1)})z_{j}^{(l-2)}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20ef4c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad74bc1",
   "metadata": {},
   "source": [
    "- Output layer:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}(z_k(s_k(w_k)))}{\\partial w_{j\\rightarrow k}} = \\delta_k^{(L)} z_k^{(L-1)} = (z_k^{(L)}-y_k) z_k^{(L-1)}.$$\n",
    "\n",
    "- Hdden layer:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}(z_j(s_j(w_j)))}{\\partial w_{i\\rightarrow j}} =\\delta_j z_j^{(l-2)} = \\Big((z_k^{(l)}-y_k) w_{j\\rightarrow k} \\sigma'(s_j^{(l-1)}) \\Big) z_j^{(l-2)}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d72592",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Backpropagation for Categorical Cross-Entropy loss with Softmax in the output layer and Sigmoid in the hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b54350",
   "metadata": {},
   "source": [
    "In this case, the gradient for the output layer is the one considering Softmax. And the gradient for the hidden layers is the one considering Sigmoid. \n",
    "\n",
    "Those results have already being calculated before.\n",
    "\n",
    "- Output layer with Softmax:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}(z_k(s_k(w_k)))}{\\partial w_{j\\rightarrow k}} = \\delta_k^{(L)} z_k^{(L-1)} = (z_k^{(L)}-y_k) z_k^{(L-1)}.$$\n",
    "\n",
    "- Hdden layer with Sigmoid:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{L}(z_j(s_j(w_j)))}{\\partial w_{i\\rightarrow j}} =\\delta_j z_j^{(l-1)}=\\left(\\sum_{k \\in l=1}^N \\delta_k^{(l+1)} w_{j\\rightarrow k}\\right) z_{j}^{(l)}(1-z_{j}^{(l)})z_j^{(l-1)}.\n",
    "\\end{align*}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "06cf633e",
    "43d6e6e4",
    "cf21b8ba",
    "74d5fcaf",
    "3YbdBPcKFfRs",
    "GOeK7f48Fkx-",
    "6he0uNVlFoVH",
    "4gJVJsFvFqrO",
    "psK5gEtJrqKw",
    "jZWMQ7sg09rE",
    "QfTvr8YR7qyD",
    "I_nTfh0f1AX8",
    "7ad71d31",
    "5fb0b399",
    "93cca21e",
    "7704cba4",
    "a5845cf2",
    "a2924544",
    "4b435331",
    "50e8cac5",
    "c52219e9",
    "903908d5",
    "e440d65b"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
